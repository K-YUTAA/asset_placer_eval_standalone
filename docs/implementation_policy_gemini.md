# 実装方針

## 1. 目的
- TODO: 　現在の画像からJSONを生成するチャットGPTのapiを用いた過程では家具の種類や家具の向き 家具の数といったところは 画像から正しく認識できるものの、家具の位置と大きさの認識精度が極端に低いため そこにLLMベースのセグメンテーションモデルであるジェミニのspatial_understandingを用いて JSONを出力させることによって家具の種類と数と向きはチャットGPTに出させつつ それをもとにその家具の種類数に一致する家具をセグメンテーションモデルに探させて座標と大きさを特定させることが本実装の目的です

## 2. 背景
- TODO: 現状の課題と前提を記載

## 3. スコープ
- TODO: 　今回実装する場所は画像からJSONデータを生成する部分のみです

## 4. 非スコープ
- TODO: 評価実験部分に関しては今回は触りません

## 5. 実装方針
- TODO: 実装方針としては今までJSONを生成させていたプロンプト1とプロンプト2の間に座標と大きさを特定させるGEMINIのモデルを入れる予定です。プロンプト1とプロンプト2の役割が少し変わるんですけどプロンプト1としては全体の座標形を指定した上で家具の種類と数また家具の機能的な向きをある程度リスト化します。そのリストをもとに家具の種類と数からGEMINIで家具の位置と大きさをJSONで出力させます。そしてそのJSONをもとに最終的な家具の位置と大きさと向きと家具を探す用のサーチプロンプトとあと部屋の大きさと壁の位置を規定していた、今まで通りのjsonを出力できるようにします。できれば部屋の大きさと壁の位置に関してもGEMINIのセグメンテーションモデルの方が精度がいいと思うのでそれもプロンプトに入れ込めるとすごくいい設計になると思います。またプロンプトも今回合計で3つのプロンプトができると思っていて、1つ目に家具の種類と数と機能的な向きを考えさせるプロンプト。2つ目に種類と数を元に座標と大きさ家具の座標と大きさを出すプロンプト。3つ目にそれらを取りまとめて部屋の形であったり家具の種類数サーチプロンプト家具の向きなどをすべて出す。3つのプロンプトができると思います。ですけどその2つ目のセグメンテーションモデルに対するプロンプトに関しては毎回ループの度に種類と数って変わってくると思うので可変になるプロンプトになると思います

## 6. データフロー
- TODO: 1回目のGPTの入力としては画像データ,寸法データ,プロンプト1です.出力としては1つのファイルにテキストもしくはJSONに家具の種類、家具の数、部屋の数この次のジェミニのセグメンテーションをさせるために必要な部屋全体を見て分かる情報を出力させます
2回目のジェミニの入力としては、画像データ、寸法データ、プロンプト2、1回目のGPTの出力です。出力としてはJSON形式でジェミニが特定した家具の位置と種類、大きさ、また部屋の大きさと部屋の中心、できれば部屋の枠が結びついているJSONデータを出力できるといいです。
　GPTの入力としては 1回目のGPTの出力と 2回目のGEMINの出力とプロンプト3です。この入力をもとに今まで作っていたような JSON 形式を出力しかつ Gemini を追加したことによって部屋の家具の位置であったり 家具の大きさをさらに精度良く出力できるようになります

## 7. 評価・検証計画
- TODO:評価検証としては 出力を元の画像にプロットしたものを出力してもらうことで私が目視で精度が改善したかどうかを判断します必要な修正に関しても私が指示を出します

## 8. リスクと対策
- TODO: 今までのgptのみを使っていたものが使用できなくならないように、オプションとしてセグメンテーションモデルを使用するようにしたいです

## 9. 実施ステップ
- TODO: 実装ステップを時系列で記載

## 10. 未決事項
- TODO: 要確認事項を記載
